<!DOCTYPE html><html translate="no" dir="ltr" lang="en-US"><head><title>ModernBERT로부터 우리는 무엇을 배워야 하는가?</title><meta charset="utf-8"><meta name="title" content="ModernBERT로부터 우리는 무엇을 배워야 하는가?"><meta name="description" content="더 큰 학습 데이터, 효율적인 파라미터 크기 조정, 그리고 깊지만 얇은 아키텍처를 가진 ModernBERT는 향후 BERT 계열 모델들의 방향을 제시합니다."><meta property="og:type" content="website"><meta property="og:url" content="https://jina.ai/news/what-should-we-learn-from-modernbert"><meta property="og:title" content="ModernBERT로부터 우리는 무엇을 배워야 하는가?"><meta property="og:description" content="더 큰 학습 데이터, 효율적인 파라미터 크기 조정, 그리고 깊지만 얇은 아키텍처를 가진 ModernBERT는 향후 BERT 계열 모델들의 방향을 제시합니다."><meta property="og:image" content="https://jina.ai/blog-banner/what-should-we-learn-from-modernbert.webp"><meta property="twitter:site" content="@JinaAI_"><meta name="twitter:creator" content="@JinaAI_"><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://jina.ai/news/what-should-we-learn-from-modernbert"><meta property="twitter:title" content="ModernBERT로부터 우리는 무엇을 배워야 하는가?"><meta property="twitter:description" content="더 큰 학습 데이터, 효율적인 파라미터 크기 조정, 그리고 깊지만 얇은 아키텍처를 가진 ModernBERT는 향후 BERT 계열 모델들의 방향을 제시합니다."><meta property="twitter:image" content="https://jina.ai/blog-banner/what-should-we-learn-from-modernbert.webp"><meta name="format-detection" content="telephone=no"><meta name="msapplication-tap-highlight" content="no"><meta name="viewport" content="user-scalable=no,initial-scale=1,maximum-scale=1,minimum-scale=1,width=device-width"><link rel="icon" type="image/png" sizes="128x128" href="/icons/favicon-128x128.png"><link rel="icon" type="image/png" sizes="96x96" href="/icons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="32x32" href="/icons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/icons/favicon-16x16.png"><link rel="icon" type="image/ico" href="/favicon.ico"><link rel="apple-touch-startup-image" media="(device-width: 428px) and (device-height: 926px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1284x2778.png"><link rel="apple-touch-startup-image" media="(device-width: 390px) and (device-height: 844px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1170x2532.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-828x1792.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1125x2436.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2688.png"><link rel="apple-touch-startup-image" media="(device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-750x1334.png"><link rel="apple-touch-startup-image" media="(device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3)" href="/icons/apple-launch-1242x2208.png"><link rel="apple-touch-startup-image" media="(device-width: 810px) and (device-height: 1080px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1620x2160.png"><link rel="apple-touch-startup-image" media="(device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1536x2048.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2224.png"><link rel="apple-touch-startup-image" media="(device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-1668x2388.png"><link rel="apple-touch-startup-image" media="(device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2)" href="/icons/apple-launch-2048x2732.png"><style>body {
      margin: 0;
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
    }</style>  <script type="module" crossorigin="" src="/assets/index-CFIL_oFr.js"></script>
  <link rel="stylesheet" crossorigin="" href="/assets/index-Db0tgwFK.css">
<link rel="modulepreload" as="script" crossorigin="" href="/assets/i18n-DaO5p_Fi.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/dynamic-import-helper-BheWnx7M.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/index-DOF-ZeYh.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/register-k1sPC4JF.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QTooltip-CbdD4mkS.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/position-engine-DkDSvH36.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/copy-to-clipboard-D1S8lOo9.js"><script src="https://www.googletagmanager.com/gtag/js?l=dataLayer&amp;id=G-4GEXCSE3MV" async=""></script><link rel="stylesheet" crossorigin="" href="/assets/prism-tomorrow-CHcPHExe.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/ko-kc2g2gNR.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/index-sFLS0J54.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/en-B3at9lMY.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/MainLayout-CNmtTF9r.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/use-dialog-plugin-component-CsTTBvRe.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/_setToArray-D-mLV1DP.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBadge-UhiIxGC3.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/PurchaseSuccessDialog-O925KtQU.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QItemLabel-DvSmXvIx.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QBtnDropdown-DkuDAuFV.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QChip-ChkjZlPE.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QMenu-Bq796LnA.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QList-BzI5dnwO.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QLinearProgress-BvDACZE8.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QLayout-D4_tDs7p.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QResizeObserver-BJwF1I9Q.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QScrollObserver-B7n1dc8c.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/TouchPan-D3_wwNMk.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/touch-BjYP5sR0.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QExpansionItem-BbAoufWX.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QSpinnerRings-BaZdpxk3.js"><link rel="stylesheet" crossorigin="" href="/assets/QSpinnerRings-0UdsL2AK.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/blogs-BBhkin09.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/ClosePopup-CFvj_zty.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/search-Co7vaquz.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/VideoDialog-B2mnQm7z.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/useRoute-DuQMcLZj.js"><link rel="stylesheet" crossorigin="" href="/assets/MainLayout-__S2BMiv.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsPage-CXarHZEm.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/QPage-bYrO6D_i.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsBadge-Yw1XlP-q.js"><link rel="modulepreload" as="script" crossorigin="" href="/assets/SXTooltip-F8MwYv0G.js"><link rel="stylesheet" crossorigin="" href="/assets/SXTooltip-vcpvmx2_.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/NewsVerticalCard-Czs8C5e3.js"><link rel="stylesheet" crossorigin="" href="/assets/NewsVerticalCard-Dppj5U4D.css"><link rel="modulepreload" as="script" crossorigin="" href="/assets/useModels-BoiqfsFc.js"><link rel="stylesheet" crossorigin="" href="/assets/NewsPage-vSZoRHSY.css"><script src="https://jina-ai-gmbh.ghost.io/public/cards.min.js" async=""></script><meta name="author" content="Nan Wang, Alex C-G"><meta property="twitter:label1" content="Written by"><meta property="twitter:data1" content="Nan Wang, Alex C-G"><meta property="twitter:label2" content="Reading time"><meta property="twitter:data2" content="10 mins read"><meta property="article:published_time" content="2025-01-22T08:31:26.000+01:00"><meta property="article:modified_time" content="2025-01-22T08:31:26.000+01:00"><script type="application/ld+json" data-qmeta="ldJson">{
  "@context": "https://schema.org",
  "@type": "Article",
  "headline": "ModernBERT로부터 우리는 무엇을 배워야 하는가?",
  "description": "더 큰 학습 데이터, 효율적인 파라미터 크기 조정, 그리고 깊지만 얇은 아키텍처를 가진 ModernBERT는 향후 BERT 계열 모델들의 방향을 제시합니다.",
  "image": [
    "https://jina.ai/blog-banner/what-should-we-learn-from-modernbert.webp"
  ],
  "datePublished": "2025-01-22T08:31:26.000+01:00",
  "dateModified": "2025-01-22T08:31:26.000+01:00",
  "author": [
    {
      "@type": "Person",
      "name": "Nan Wang",
      "url": "https://jina-ai-gmbh.ghost.io/author/nan/"
    },
    {
      "@type": "Person",
      "name": "Alex C-G",
      "url": "https://jina-ai-gmbh.ghost.io/author/alexcg/"
    }
  ],
  "publisher": {
    "@type": "Organization",
    "name": "Jina AI",
    "url": "https://jina.ai"
  }
}</script><script prerender-ignore id=usercentrics-cmp src=https://web.cmp.usercentrics.eu/ui/loader.js data-settings-id=w5v6v2pJsC3wdR async></script><script prerender-ignore src="https://www.googletagmanager.com/gtag/js?id=G-9T52NXDS9T" async></script><script prerender-ignore>window.dataLayer = window.dataLayer || [];

  function gtag() {
    dataLayer.push(arguments);
  }

  gtag('js', new Date());

  gtag('config', 'G-9T52NXDS9T');</script></head><body class="desktop no-touch body--dark"><div id="q-app" data-v-app class="hidden"><div data-v-478b3f77="" class="q-layout q-layout--standard" tabindex="-1" style="min-height: 600px;"><header data-v-478b3f77="" class="q-header q-layout__section--marginal fixed-top lock-blur bg-transparent print-hide"><div data-v-478b3f77="" class="q-toolbar row no-wrap items-center q-px-none relative-position" role="toolbar"><a data-v-478b3f77="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable q-btn--dense no-border-radius self-stretch q-px-md q-pa-none" tabindex="0" href="/" style="font-size: 2em;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><img src="/Jina - Dark.svg"></i></span></a><div data-v-478b3f77="" class="q-space"></div><button data-v-478b3f77="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle text- q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">search</i></span></button><button data-v-478b3f77="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">reorder</i></span></button></div></header><div data-v-478b3f77="" class="q-drawer-container"><div class="q-drawer__opener fixed-right" aria-hidden="true"></div><div class="fullscreen q-drawer__backdrop hidden" aria-hidden="true" style="background-color: rgba(0, 0, 0, 0);"></div><aside class="q-drawer q-drawer--right q-drawer--bordered q-drawer--dark q-dark q-layout--prevent-focus fixed q-drawer--on-top q-drawer--mobile q-drawer--top-padding" style="width: 300px; transform: translateX(300px);"><div class="q-drawer__content fit scroll column"><div data-v-478b3f77="" class="q-scrollarea q-scrollarea--dark" style="flex-grow: 1;"><div class="q-scrollarea__container scroll relative-position fit hide-scrollbar"><div class="q-scrollarea__content absolute"><div data-v-478b3f77="" class="q-list q-list--dark" role="list"><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--active q-router-link--active q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/news"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">소식</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/models"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">모델</div></a><div data-v-478b3f77="" class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_d2f0c8a9-2602-4eb4-9ec4-2357148f54e8" aria-label="Expand &quot;제품&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">제품</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_d2f0c8a9-2602-4eb4-9ec4-2357148f54e8" style="display: none;"><div data-v-478b3f77="" class="q-list q-list--dark" role="list" label="제품"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/deepsearch"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20width='240'%20height='240'%20viewBox='0%200%20240%20240'%20fill='none'%20xmlns='http://www.w3.org/2000/svg'%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M123.395%20131.064L162.935%20102.948L154.175%2087.776L123.395%20131.064ZM146.664%2074.7669L121.428%20129.927L129.479%2045.0007L146.664%2074.7669ZM117.189%20137.27L36%20195H76.1387L117.189%20137.27ZM93.2635%20195L119.156%20138.405L113.791%20195H93.2635ZM177.409%20128.018L124.531%20133.031L168.649%20112.846L177.409%20128.018ZM38.4785%20170.794L116.053%20135.302L55.6643%20141.027L38.4785%20170.794ZM184.92%20141.027L202.105%20170.793L124.531%20135.302L184.92%20141.027ZM116.053%20133.031L63.1751%20128.018L71.9347%20112.846L116.053%20133.031ZM123.395%20137.269L204.584%20195H164.446L123.395%20137.269ZM77.6493%20102.948L117.189%20131.063L86.4089%2087.7758L77.6493%20102.948ZM121.428%20138.406L126.793%20195H147.321L121.428%20138.406ZM119.156%20129.927L93.9197%2074.7667L111.105%2045L119.156%20129.927Z'%20fill='white'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">심층 검색</div><div class="q-item__label q-item__label--caption text-caption">검색하고, 읽고, 추론하여 가장 좋은 답을 찾으세요.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/reader"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/reader-D06QTWF1.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">리더</div><div class="q-item__label q-item__label--caption text-caption">URL을 읽거나 더 큰 모델에 대한 더 나은 통찰력을 검색하세요.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/embedding-DzEuY8_E.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">벡터 모델</div><div class="q-item__label q-item__label--caption text-caption">세계적 수준의 다중 모드 다중 언어 임베딩.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/reranker"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 56.2493%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--current" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/assets/reranker-DudpN0Ck.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__loading absolute-full flex flex-center"><svg class="q-spinner q-spinner-mat" width="1em" height="1em" viewBox="25 25 50 50"><circle class="path" cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-miterlimit="10"></circle></svg></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">재배열자</div><div class="q-item__label q-item__label--caption text-caption">검색 관련성을 극대화하는 세계적 수준의 신경 검색기입니다.</div></div></a><div class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard text-dim"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_baac2326-f66c-4d41-a350-f8b005c3c500" aria-label="Expand &quot;더&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">더</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_baac2326-f66c-4d41-a350-f8b005c3c500" style="display: none;"><div class="q-list q-list--dark" role="list"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/classifier" target=""><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20width='240'%20height='240'%20viewBox='0%200%20240%20240'%20fill='none'%20xmlns='http://www.w3.org/2000/svg'%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M152.304%20184.388L184.388%20152.304H152.304V184.388ZM146.922%20190.885V149.613C146.922%20148.127%20148.127%20146.922%20149.613%20146.922H190.886C193.283%20146.922%20194.484%20149.821%20192.789%20151.516L151.516%20192.788C149.821%20194.484%20146.922%20193.283%20146.922%20190.885Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M152.304%20133.927L184.388%20101.843H152.304V133.927ZM146.922%20140.424V99.1521C146.922%2097.6657%20148.127%2096.4608%20149.613%2096.4608H190.886C193.283%2096.4608%20194.484%2099.3597%20192.789%20101.055L151.516%20142.327C149.821%20144.023%20146.922%20142.822%20146.922%20140.424Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3828%20184.806L83.4668%20152.722H51.3828V184.806ZM46.0003%20191.303V150.031C46.0003%20148.545%2047.2053%20147.34%2048.6916%20147.34H89.964C92.3616%20147.34%2093.5624%20150.239%2091.867%20151.934L50.5946%20193.206C48.8992%20194.902%2046.0003%20193.701%2046.0003%20191.303Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%20184.388L133.927%20152.304H101.843V184.388ZM96.4608%20190.885V149.613C96.4608%20148.127%2097.6657%20146.922%2099.152%20146.922H140.424C142.822%20146.922%20144.023%20149.821%20142.327%20151.516L101.055%20192.788C99.3597%20194.484%2096.4608%20193.283%2096.4608%20190.885Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%20133.927L133.927%20101.843H101.843V133.927ZM96.4608%20140.424V99.1521C96.4608%2097.6657%2097.6657%2096.4608%2099.152%2096.4608H140.424C142.822%2096.4608%20144.023%2099.3597%20142.327%20101.055L101.055%20142.327C99.3597%20144.023%2096.4608%20142.822%2096.4608%20140.424Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M101.843%2083.4664L133.927%2051.3825H101.843V83.4664ZM96.4608%2089.9637V48.6913C96.4608%2047.2049%2097.6657%2046%2099.152%2046H140.424C142.822%2046%20144.023%2048.8989%20142.327%2050.5943L101.055%2091.8667C99.3597%2093.5621%2096.4608%2092.3613%2096.4608%2089.9637Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3828%20132.808L83.4668%20100.725H51.3828V132.808ZM46.0003%20139.306V98.0333C46.0003%2096.547%2047.2053%2095.3421%2048.6916%2095.3421H89.964C92.3616%2095.3421%2093.5624%2098.2409%2091.867%2099.9363L50.5946%20141.209C48.8992%20142.904%2046.0003%20141.703%2046.0003%20139.306Z'%20fill='white'/%3e%3cpath%20d='M190.891%2046H149.619C147.221%2046%20146.02%2048.8989%20147.716%2050.5943L188.988%2091.8667C190.683%2093.5621%20193.582%2092.3613%20193.582%2089.9637V48.6913C193.582%2047.2049%20192.377%2046%20190.891%2046Z'%20fill='white'/%3e%3cpath%20fill-rule='evenodd'%20clip-rule='evenodd'%20d='M51.3826%2083.4664L83.4665%2051.3825H51.3826V83.4664ZM46.0001%2089.9637V48.6913C46.0001%2047.2049%2047.205%2046%2048.6914%2046H89.9638C92.3614%2046%2093.5621%2048.8989%2091.8668%2050.5943L50.5944%2091.8667C48.899%2093.5621%2046.0001%2092.3613%2046.0001%2089.9637Z'%20fill='white'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">분류자</div><div class="q-item__label q-item__label--caption text-caption">이미지와 텍스트의 제로샷 및 퓨샷 분류.</div></div></a><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/segmenter" target=""><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div class="q-img q-img--menu" role="img"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="data:image/svg+xml,%3csvg%20xmlns='http://www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%20width='320'%20zoomAndPan='magnify'%20viewBox='0%200%20240%20239.999995'%20height='320'%20preserveAspectRatio='xMidYMid%20meet'%20version='1.0'%3e%3cpath%20fill='%23ffffff'%20d='M%20132.328125%2039%20L%20144.652344%2060.351562%20L%20132.328125%2081.699219%20L%20107.675781%2081.699219%20L%2095.347656%2060.351562%20L%20107.675781%2039%20Z%20M%20184.96875%2058.523438%20L%20202%2088.023438%20L%20184.96875%20117.527344%20L%20153.011719%20117.527344%20L%20138.085938%20143.375%20L%20154.066406%20171.050781%20L%20137.03125%20200.554688%20L%20102.964844%20200.554688%20L%2085.933594%20171.050781%20L%20101.910156%20143.375%20L%2086.988281%20117.527344%20L%2055.03125%20117.527344%20L%2038%2088.027344%20L%2055.03125%2058.523438%20L%2089.097656%2058.523438%20L%20105.074219%2086.199219%20L%20134.921875%2086.199219%20L%20150.902344%2058.523438%20Z%20M%2057.140625%20113.875%20L%2086.988281%20113.875%20L%20101.914062%2088.023438%20L%2086.988281%2062.175781%20L%2057.140625%2062.175781%20L%2042.21875%2088.027344%20Z%20M%20105.074219%20141.550781%20L%2090.152344%20115.703125%20L%20105.078125%2089.851562%20L%20134.921875%2089.851562%20L%20149.847656%20115.699219%20L%20134.925781%20141.550781%20Z%20M%20138.085938%2088.023438%20L%20153.011719%2062.175781%20L%20182.859375%2062.175781%20L%20197.78125%2088.023438%20L%20182.859375%20113.875%20L%20153.011719%20113.875%20Z%20M%20105.074219%20145.203125%20L%2090.152344%20171.050781%20L%20105.074219%20196.902344%20L%20134.921875%20196.902344%20L%20149.847656%20171.050781%20L%20134.921875%20145.203125%20Z%20M%2096.71875%20143.375%20L%2084.390625%20122.027344%20L%2059.738281%20122.027344%20L%2047.414062%20143.375%20L%2059.738281%20164.726562%20L%2084.390625%20164.726562%20Z%20M%20192.585938%20143.375%20L%20180.261719%20122.023438%20L%20155.605469%20122.023438%20L%20143.28125%20143.375%20L%20155.605469%20164.726562%20L%20180.261719%20164.726562%20Z%20M%20192.585938%20143.375%20'%20fill-opacity='1'%20fill-rule='evenodd'/%3e%3c/svg%3e" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">얇게 써는 기계</div><div class="q-item__label q-item__label--caption text-caption">긴 텍스트를 청크 또는 토큰으로 분할합니다.</div></div></a></div></div></div></div><hr class="q-separator q-separator--horizontal q-separator--dark" aria-orientation="horizontal"><a class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://docs.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">API 문서</div><div class="q-item__label q-item__label--caption text-caption">AI 프로그래밍 어시스턴트 IDE 또는 대형 모델에 대한 코드를 자동으로 생성합니다.</div></div><div class="q-item__section column q-item__section--side justify-center"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a></div></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><div data-v-478b3f77="" class="q-expansion-item q-item-type q-expansion-item--collapsed q-expansion-item--standard"><div class="q-expansion-item__container relative-position"><div class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="button" tabindex="0" aria-expanded="false" aria-controls="f_ea4ece00-8b18-456d-b540-9093955a364f" aria-label="Expand &quot;회사&quot;"><div class="q-focus-helper" tabindex="-1"></div><div class="q-item__section column q-item__section--main justify-center"><div class="q-item__label">회사</div></div><div class="q-item__section column q-item__section--side justify-center q-focusable relative-position cursor-pointer"><i class="q-icon notranslate material-symbols material-symbols-sharp q-expansion-item__toggle-icon" aria-hidden="true" role="presentation">keyboard_arrow_down</i></div></div><div class="q-expansion-item__content relative-position" id="f_ea4ece00-8b18-456d-b540-9093955a364f" style="display: none;"><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/about-us"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">회사 소개</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/contact-sales"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">영업팀에 문의</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/internship"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">인턴 프로그램</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="https://app.dover.com/jobs/jinaai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">우리와 함께</div><div data-v-478b3f77="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i data-v-478b3f77="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/logo-Jina-1024.zip" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">로고 다운로드</div><div data-v-478b3f77="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i data-v-478b3f77="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">open_in_new</i></div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable q-pa-md" role="listitem" tabindex="0" href="/legal"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">이용약관</div></a></div><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--top absolute-top" aria-orientation="horizontal"><hr class="q-separator q-separator--horizontal q-separator--dark q-expansion-item__border q-expansion-item__border--bottom absolute-bottom" aria-orientation="horizontal"></div></div><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="/api-dashboard?login=true" label="로그인"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">로그인</div><div data-v-478b3f77="" class="q-item__section column q-item__section--side justify-center"><i data-v-478b3f77="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation">login</i></div></a><div data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><label data-v-478b3f77="" class="q-field row no-wrap items-start q-field--borderless q-select q-field--auto-height q-select--without-input q-select--without-chips q-select--single q-field--square q-field--dark full-width" for="f_be62d2a3-f813-4a86-a7e4-bda4a5370f96"><div class="q-field__inner relative-position col self-stretch"><div class="q-field__control relative-position row no-wrap" tabindex="-1"><div class="q-field__control-container col relative-position row no-wrap q-anchor--skip"><div class="q-field__native row items-center"><span></span><input class="q-select__focus-target" id="f_be62d2a3-f813-4a86-a7e4-bda4a5370f96" readonly="" tabindex="0" role="combobox" aria-readonly="false" aria-autocomplete="none" aria-expanded="false" aria-controls="f_be62d2a3-f813-4a86-a7e4-bda4a5370f96_lb" value=""></div></div><div class="q-field__append q-field__marginal row no-wrap items-center q-anchor--skip"><i class="q-icon notranslate material-symbols material-symbols-sharp q-select__dropdown-icon" aria-hidden="true" role="presentation">language</i></div></div></div></label></div></div></div></div><div class="q-scrollarea__bar q-scrollarea__bar--v absolute-right q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__bar q-scrollarea__bar--h absolute-bottom q-scrollarea__bar--invisible" aria-hidden="true"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--v absolute-right q-scrollarea__thumb--invisible" aria-hidden="true" style="top: 0px; height: 600px; right: 0px;"></div><div class="q-scrollarea__thumb q-scrollarea__thumb--h absolute-bottom q-scrollarea__thumb--invisible" aria-hidden="true" style="opacity: 0; left: 0px; width: 299px; bottom: 0px;"></div></div></div></aside></div><div data-v-478b3f77="" class="q-page-container squeeze-top" style="padding-top: 56px;"><main data-v-c36e4d4e="" class="q-page" style="min-height: 100vh;"><div data-v-c36e4d4e="" class="row full-width relative-position justify-end"><div data-v-c36e4d4e="" class="fixed-left q-pl-md" style="width: 300px; top: 100px; z-index: 1; display: none;"><div data-v-c36e4d4e="" class="q-list q-list--dark q-mx-sm" role="list"><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">ModernBERT의 매개변수 효율성</div></div></div><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">ModernBERT의 코드 모델링</div></div></div><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">ModernBERT의 긴 컨텍스트 처리</div></div></div><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">쓴 교훈?</div></div></div><div data-v-c36e4d4e="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable relative-position q-pa-md text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-c36e4d4e="" class="q-item__section column q-item__section--main justify-center q-ml-md"><div data-v-c36e4d4e="" class="q-item__label">결론</div></div></div></div></div><div data-v-c36e4d4e="" class="col-12 col-md-10 col-lg-12"><div data-v-c36e4d4e="" class="row justify-center q-pt-xl q-mt-xl"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">기술 기사</div></div></div></div><div data-v-c36e4d4e="" class="row justify-center"><div data-v-c36e4d4e="" class="col-11 col-sm-9 cold-md-7 col-lg-6 column items-center q-pt-md q-mt-md q-gutter-y-xl"><div data-v-c36e4d4e="" class="q-item__label q-item__label--caption text-caption text-white q-mt-sm text-center q-pt-xl q-mt-xl">1월 22, 2025</div><h1 data-v-c36e4d4e="" class="text-weight-medium text-center q-px-md my-title">ModernBERT로부터 우리는 무엇을 배워야 하는가?</h1><div data-v-c36e4d4e="" class="col row justify-center"><div data-v-c36e4d4e="" class="q-item__label q-item__label--caption text-caption col-8 col-sm-7 col-md-6 text-center text-dim" style="font-size: 1rem;">더 큰 학습 데이터, 효율적인 파라미터 크기 조정, 그리고 깊지만 얇은 아키텍처를 가진 ModernBERT는 향후 BERT 계열 모델들의 방향을 제시합니다.</div></div><div data-v-c36e4d4e="" class="q-card q-card--dark q-dark q-card--flat no-shadow" style="width: 100%;"><div data-v-c36e4d4e="" class="q-img q-img--menu" role="img"><div style="padding-bottom: 52.5%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2025/01/modernbert.png" style="object-fit: contain; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div><div data-v-c36e4d4e="" class="row justify-center"><div data-v-c36e4d4e="" class="col-10 col-sm-9 cold-md-7 col-lg-6 q-py-md"><div data-v-c36e4d4e="" class="col row justify-start items-center q-gutter-sm text-overline"><div data-v-61d959b7="" data-v-c36e4d4e="" class="relative-position row items-center" style="height: 26px; width: 47px;"><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 0px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Nan Wang"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Nan Wang" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2025/01/avartar_2024.jpeg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div><div data-v-61d959b7="" class="q-avatar overlapping" style="font-size: 24px; left: 18px;"><div class="q-avatar__content row flex-center overflow-hidden"><div data-v-61d959b7="" class="q-img q-img--menu" role="img" aria-label="Alex C-G"><div style="padding-bottom: 100%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" alt="Alex C-G" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="https://jina-ai-gmbh.ghost.io/content/images/2022/09/alex.jpg" style="object-fit: cover; object-position: 50% 50%; cursor: help;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></div></div><div data-v-c36e4d4e="" class="q-item__label">Nan Wang, Alex C-G • 10 독서 시간</div></div></div></div><div data-v-c36e4d4e="" class="row justify-center"><div data-v-c36e4d4e="" class="col-10 col-sm-9 cold-md-7 col-lg-6 q-mb-xl q-pb-xl"><article data-v-c36e4d4e="" class="article"><section data-v-c36e4d4e="" class="gh-content"><p>2018년, Google이 BERT를 발표했을 때 이는 현재의 LLM 물결이 오기 훨씬 전부터 NLP 분야의 게임 체인저였습니다. 지금도 많은 Small Language Model들이 BERT를 기반으로 구축되어 있습니다. 2024년 12월, <a href="https://huggingface.co/blog/modernbert" rel="noreferrer">ModernBERT</a>는 최근 LLM 개발에서 배운 것들을 이러한 작은 모델들에 적용했습니다. 주요 변화는? 더 나은 매개변수 효율성, 코드 이해 및 긴 문맥 처리입니다.</p><p>이 포스트에서는 우리가 잘 알고 있는 두 모델과 ModernBERT를 비교해보겠습니다: <code>jina-XLM-RoBERTa</code>(<a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v3" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v3</span></a>의 다국어 백본)와 <code>RoBERTa-large</code>입니다. 각 모델을 살펴보겠습니다:</p><ul><li><strong>ModernBERT</strong>(2024년 12월)는 최근 출시된 SLM으로, Answer.AI, LightOn, HuggingFace가 공동으로 개발했습니다. 8,192 토큰 문맥 윈도우를 위한 RoPE와 <a href="https://arxiv.org/abs/2002.05202">GeGLU 레이어</a>와 같은 현대적 최적화를 활용하여 효율성을 유지하면서 성능을 향상시켰습니다.</li><li><a href="https://huggingface.co/jinaai/xlm-roberta-flash-implementation"><strong><code>jina-XLM-RoBERTa</code></strong></a><strong></strong>(2024년 9월)는 Meta의 <a href="https://huggingface.co/docs/transformers/en/model_doc/xlm-roberta"><code>XLM-RoBERTa</code></a>를 기반으로 한 다국어 텍스트 임베딩 모델입니다. 원래 <code>XLM-RoBERTa</code>가 XLM 대규모 다국어 데이터셋을 사용하여 <code>RoBERTa</code>를 개선한 반면, <code>jina-XLM-RoBERTa</code>는 확장된 문맥 학습, <a href="https://arxiv.org/abs/2104.09864">RoPE</a> 구현, <a href="https://arxiv.org/abs/2307.08691">FlashAttention-2</a> 지원으로 한 걸음 더 나아갔습니다. 이 모델은 <a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v3" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v3</span></a>의 백본으로 사용됩니다.</li><li><a href="https://huggingface.co/FacebookAI/roberta-large"><strong><code>RoBERTa-large</code></strong></a>(2019년 7월)는 Meta가 개발한 BERT의 개선 버전으로 3억 5500만 개의 매개변수를 가지고 있습니다. 확장된 학습, 더 큰 데이터셋, 동적 마스킹과 같은 혁신을 통해 <a href="https://gluebenchmark.com/">GLUE</a>, <a href="https://rajpurkar.github.io/SQuAD-explorer/">SQuAD</a>, <a href="https://arxiv.org/abs/1704.04683">RACE</a>를 포함한 주요 벤치마크에서 인상적인 결과를 달성했습니다. 이는 텍스트 분류부터 질문 답변까지 다양한 NLP 작업에 적합합니다.</li></ul><p>이 모델들을 세 가지 핵심 측면에서 비교함으로써, 모델 개발자들을 위한 ModernBERT의 효과적인 설계 선택을 강조하고 향후 BERT 유사 모델을 위한 핵심 개발 통찰을 식별하고자 합니다. 또한 <a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v3" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v3</span></a> 개발에서 얻은 교훈을 공유하고 <code>jina-embeddings-v4</code>와 <code>jina-reranker-v3</code>를 위한 계획된 개선 사항을 논의하겠습니다.</p><h2 id="modernberts-parameter-efficiency" style="position: relative;"><a href="#modernberts-parameter-efficiency" title="ModernBERT의 매개변수 효율성" id="anchor-modernberts-parameter-efficiency"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>ModernBERT의 매개변수 효율성</h2><p>먼저 ModernBERT의 매개변수 효율성 접근 방식을 살펴보겠습니다 - 이는 최근 LLM 개발에서 얻은 여러 핵심 통찰을 가져왔습니다. ModernBERT는 깊지만 얇은 아키텍처, 제어된 어휘 크기, 작은 모델에서 시작하는 점진적 모델 업스케일링이라는 세 가지 핵심 전략을 활용합니다.</p><h3 id="deep-and-thin-architecture" style="position: relative;"><a href="#deep-and-thin-architecture" title="Deep-And-Thin 아키텍처" id="anchor-deep-and-thin-architecture"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>Deep-And-Thin 아키텍처</h3><p>ModernBERT-large는 28개 레이어로 더 깊어진 반면, <code>jina-XLM-RoBERTa</code>와 <code>RoBERTa-large</code>는 24개로 운영됩니다. 흥미로운 점은 추가 레이어에도 불구하고 <code>RoBERTa-large</code>와 매개변수 수가 비슷하다는 것입니다. <code>jina-XLM-RoBERTa</code>는 89개 언어를 처리해야 하기 때문에 더 많은 매개변수가 필요한 반면, 다른 두 모델은 영어에만 집중합니다.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2025/01/deep_and_thin-dark-architecture-outlines-1.svg" class="kg-image" alt="" width="1389" height="547" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">작은 LLM에서는 너비(hidden unit 수)보다 깊이(레이어 수)가 더 중요합니다. deep-and-thin 모델 구조는 추상적 개념을 포착하는데 뛰어나 우수한 최종 성능을 보입니다.</span></figcaption></figure><p>트랜스포머의 매개변수 대부분은 어텐션과 완전연결 레이어에서 옵니다. ModernBERT는 "얇게" 가면서도 경쟁력을 유지합니다 - RoBERTa-large가 24개 레이어에 걸쳐 4,096 hidden unit을 사용하는 것에 비해 28개 레이어에 걸쳐 2,624 hidden unit을 사용합니다. 이 "더 깊지만" 얇은 구성으로 모델을 비대화하지 않고도 성능 목표를 달성할 수 있습니다.</p>

<table>
<thead>
<tr>
<th></th>
<th>ModernBERT-large</th>
<th><code>jina-XLM-RoBERTa</code></th>
<th><code>RoBERTa-large</code></th>
</tr>
</thead>
<tbody>
<tr>
<td>Parameters</td>
<td>400M</td>
<td>550M</td>
<td>355M</td>
</tr>
<tr>
<td>Hidden states</td>
<td>1,024</td>
<td>1,024</td>
<td>1,024</td>
</tr>
<tr>
<td>Intermediate dims</td>
<td>2,624</td>
<td>4,096</td>
<td>4,096</td>
</tr>
<tr>
<td>Attention heads</td>
<td>16</td>
<td>16</td>
<td>16</td>
</tr>
<tr>
<td>Layers</td>
<td>28</td>
<td>24</td>
<td>24</td>
</tr>
<tr>
<td>Vocabulary size</td>
<td>50,368</td>
<td>250,002</td>
<td>50,265</td>
</tr>
</tbody>
</table>

<p>이 접근 방식은 Meta의 <a href="https://openreview.net/pdf?id=EIGbXbxcUQ">MobileLLM</a> 연구와 일치하는데, 이 연구는 작은 모델의 경우 복잡한 패턴을 포착하고 성능을 향상시키는 데 있어 너비보다 깊이가 더 중요하다는 것을 발견했습니다. 본질적으로, 병렬 처리를 위해 더 넓은 레이어를 갖는 것보다 더 많은 트랜스포머 레이어를 통해 정보를 처리하는 능력이 더 가치가 있다는 것입니다.</p><p>이 deep-and-thin 아키텍처의 성능을 데이터로 살펴보겠습니다.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2025/01/performance_comparison_general.v3.svg" class="kg-image" alt="" width="872" height="371" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">전통적인 shallow-fat 아키텍처를 사용하는 비슷한 모델들과 비교했을 때, ModernBERT는 비슷한 매개변수 수를 유지하면서도 검색과 STS 같은 주요 작업에서 더 나은 결과를 보여줍니다.</span></figcaption></figure>

<table>
<thead>
<tr>
<th></th>
<th>ModernBERT-large</th>
<th><code>jina-XLM-RoBERTa</code></th>
<th><code>RoBERTa-large</code></th>
</tr>
</thead>
<tbody>
<tr>
<td>STS12</td>
<td>72.6</td>
<td><strong>72.7</strong></td>
<td>68.9</td>
</tr>
<tr>
<td>STS13</td>
<td><strong>84.9</strong></td>
<td>83.9</td>
<td>81.0</td>
</tr>
<tr>
<td>STS14</td>
<td>77.5</td>
<td><strong>77.7</strong></td>
<td>74.8</td>
</tr>
<tr>
<td>STS15</td>
<td>84.8</td>
<td><strong>85.8</strong></td>
<td>84.1</td>
</tr>
<tr>
<td>STS16</td>
<td>79.4</td>
<td><strong>79.6</strong></td>
<td>78.6</td>
</tr>
<tr>
<td>STS17</td>
<td><strong>87.5</strong></td>
<td>87.2</td>
<td>87.2</td>
</tr>
<tr>
<td>TRECCOVID</td>
<td><strong>61.1</strong></td>
<td>59.6</td>
<td>49.3</td>
</tr>
<tr>
<td>FiQA</td>
<td><strong>44.4</strong></td>
<td>40.0</td>
<td>40.7</td>
</tr>
<tr>
<td>NFCorpus</td>
<td><strong>32.6</strong></td>
<td>30.6</td>
<td>27.9</td>
</tr>
<tr>
<td>SciFact</td>
<td><strong>68.6</strong></td>
<td>65.5</td>
<td>63.1</td>
</tr>
<tr>
<td>Average</td>
<td><strong>69.3</strong></td>
<td>68.2</td>
<td>65.6</td>
</tr>
</tbody>
</table>

<p><code>jina-XLM-RoBERTa</code>를 예로 들어보면 - <code>RoBERTa-large</code>의 shallow-fat 아키텍처를 기반으로 하되 어휘를 50K에서 250K 토큰으로 늘리고 더 많은 데이터로 학습했습니다. 그럼에도 ModernBERT가 약간 앞서는데, 이는 아키텍처의 변화가 효율성 측면에서 실질적인 차이를 만들어내고 있음을 시사합니다.</p><h3 id="vocabulary-size-matters" style="position: relative;"><a href="#vocabulary-size-matters" title="어휘 크기의 중요성" id="anchor-vocabulary-size-matters"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>어휘 크기의 중요성</h3><p>먼저, 트랜스포머에서 어휘 매개변수가 어떻게 계산되는지 살펴보겠습니다. 모든 트랜스포머에서 <code>어휘 매개변수 = 고유 토큰 수 × hidden size</code>입니다. <code>jina-XLM-RoBERTa</code>를 예로 들면: 250K 토큰과 1,024 차원으로, 실제 언어 작업을 처리하기도 전에 어휘 인코딩만을 위해 256M 매개변수가 필요합니다!</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2025/01/tokenizer-dark-outline.svg" class="kg-image" alt="" width="3757" height="715" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">트랜스포머에서 첫 번째 레이어는 토큰을 가중치 행렬, 즉 어휘 가중치를 사용하여 은닉 상태로 매핑합니다. 모든 UTF-8 코드 포인트(1,112,064)를 1,024 차원의 은닉층과 함께 사용한다고 가정하면, 토큰 변환만을 위해 거대한 </span><code spellcheck="false" style="white-space: pre-wrap;"><span>1,112,064 × 1,024 = 1 B</span></code><span style="white-space: pre-wrap;"> 개의 파라미터가 필요합니다. 대형 LLM(100B+ 파라미터)은 이러한 오버헤드를 처리할 수 있지만, 작은 모델에는 심각한 제약이 됩니다. 이것이 바로 우리가 BPE와 같은 토크나이저를 사용하여 일반적인 UTF-8 코드 포인트를 단일 토큰으로 효율적으로 병합하는 이유입니다.</span></figcaption></figure><p>하지만 여기서 중요한 점은 다음과 같습니다: <strong>어휘 가중치는 어텐션 메커니즘에 기여하지 않으며, 단순히 조회 테이블일 뿐입니다.</strong> 고정된 파라미터 예산으로 작동하는 SLM의 경우, 더 큰 어휘는 실제 언어 처리를 수행하는 어텐션 레이어에 사용할 수 있는 파라미터가 줄어든다는 것을 의미합니다. 이는 영어 전용 ModernBERT-large가 더 작음에도 불구하고 다국어 <code>jina-XLM-RoBERTa</code>보다 성능이 더 우수한 이유를 설명합니다 - <code>jina-XLM-RoBERTa</code>는 다중 언어를 지원하기 위해 더 많은 파라미터(47%!)를 할당합니다. ModernBERT의 집중된 어휘는 성능을 개선할 뿐만 아니라 추론 속도도 향상시켜 리소스가 제한된 애플리케이션에 특히 효과적입니다.</p><p>이제 어휘 가중치를 제외한 <em>핵심</em> 모델 파라미터만 살펴보면, ModernBERT는 실제로 동료들보다 더 많은 연산 능력을 가지고 있습니다: ModernBERT는 <code>jina-XLM-RoBERTa</code>보다 19% 더 많은 파라미터를, <code>RoBERTa-large</code>보다 15% 더 많은 파라미터를 <em>실제</em> 언어 모델링에 할당합니다!</p>

<table>
<thead>
<tr>
<th>모델 사양</th>
<th>ModernBERT-large</th>
<th><code>jina-XLM-RoBERTa</code></th>
<th><code>RoBERTa-large</code></th>
</tr>
</thead>
<tbody>
<tr>
<td>언어 지원</td>
<td>영어만</td>
<td>89개 언어</td>
<td>영어만</td>
</tr>
<tr>
<td>어휘 크기</td>
<td>50.4K</td>
<td>250K</td>
<td>50.3K</td>
</tr>
<tr>
<td>총 파라미터</td>
<td>400M</td>
<td>550M</td>
<td>355M</td>
</tr>
<tr>
<td>어휘 파라미터</td>
<td>51M</td>
<td>256M</td>
<td>51M</td>
</tr>
<tr>
<td>어휘 파라미터 비율</td>
<td>13%</td>
<td>47%</td>
<td>14%</td>
</tr>
<tr>
<td>핵심 모델 파라미터</td>
<td><b>349M</b></td>
<td>294M</td>
<td>304M</td>
</tr>
</tbody>
</table>

<h3 id="model-upscaling-by-weight-tiling" style="position: relative;"><a href="#model-upscaling-by-weight-tiling" title="&quot;가중치 타일링&quot;을 통한 모델 확장" id="anchor-model-upscaling-by-weight-tiling"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>"가중치 타일링"을 통한 모델 확장</h3><p><a href="https://huggingface.co/jinaai/jina-bert-implementation"><code>jina-BERT-v2</code></a> 백본을 구축하면서, 처음부터 SLM을 훈련하는 것이 리소스 집약적이고 복잡하다는 것을 발견했습니다. ModernBERT는 <strong>가중치 타일링</strong>이라는 스마트한 초기화 접근 방식으로 이 문제를 해결합니다 - 본질적으로 더 작은 base 버전의 가중치로부터 ModernBERT-large를 부트스트랩합니다.</p><p>이 기술은 완전히 새로운 것은 아닙니다 - DeepMind의 <a href="https://gpt3demo.com/apps/deepmind-gopher">Gopher</a> 작업을 기반으로 하며 Microsoft의 <a href="https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/">Phi-2 모델</a>에서도 나타납니다. 하지만 여기서의 적용은 SLM 훈련 병목 현상을 해결하는 데 특히 효과적입니다.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2025/01/deep_and_thin-dark.svg" class="kg-image" alt="" width="1877" height="1308" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">ModernBERT는 Gopher 팀의 깊이 초기화 전략을 사용하여 22개에서 28개 레이어로 확장됩니다. 추가 레이어(23-28)의 경우, ModernBERT-base의 원래 22개 레이어의 가중치를 사용하여 각 레이어를 초기화합니다. 각 레이어의 가중치 행렬에 대해서는 Phi-2의 중앙 타일링 접근 방식을 사용합니다. 작동 방식은 다음과 같습니다: ModernBERT-base 가중치를 가져와서 ModernBERT-large의 행렬 중앙에 배치합니다. 여전히 비어 있는 가장자리는 어떻게 할까요? 원래 가중치를 순환적으로 감싸서 채웁니다.</span></figcaption></figure><p>이 초기화 전략은 ModernBERT-large에 상당한 이점을 제공합니다 - 처음부터 시작하는 대신 더 작은 버전에서 사전 학습된 패턴을 활용합니다. 이는 <a href="https://arxiv.org/pdf/2112.11446">이 크기 범위의 언어 모델을 확장하는 데 특히 효과적</a>임이 입증되었습니다.</p><blockquote>우리는 웜 스타트된 모델이 (추가된 파라미터로 인한) 높은 초기 손실에서 빠르게 회복하여 기본 모델과 매우 가까운 손실에 도달한다는 것을 발견했습니다. 417M 파라미터를 3배 이상 확장하면서도 수렴할 때까지 처음부터 훈련된 동등한 신규 모델보다 더 나은 성능을 유지할 수 있었습니다. 이는 이득이 훈련 초기에만 국한되지 않았음을 의미합니다. 그러나 더 큰 크기에서는, 특히 너비 확장에서 수렴 시 달성되는 상대적 이득이 감소합니다.</blockquote><p>순환적 가중치 래핑은 단순한 편의성이 아닙니다 - 어텐션 행렬이 자연스럽게 주기적 패턴을 보이는 방식과 잘 부합합니다. Gopher의 연구는 이 접근 방식이 SLM(9B 미만 파라미터)에서 특히 빛을 발하지만, 더 큰 모델 영역으로 이동할수록 이점이 점차 감소하기 시작한다는 것을 보여줍니다.</p><h2 id="modernberts-code-modeling" style="position: relative;"><a href="#modernberts-code-modeling" title="ModernBERT의 코드 모델링" id="anchor-modernberts-code-modeling"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>ModernBERT의 코드 모델링</h2><p>ModernBERT는 코드에 최적화된 토크나이저와 훈련 데이터를 통해 코드 이해에 특화된 접근 방식을 제공합니다. 이러한 코드 처리를 위한 미세 조정은 이해와 검색 작업 모두에서 효과를 발휘합니다.</p><p>우리는 <code>jina-embeddings-v2-code</code> 코퍼스를 사용하여 세 가지 모델을 백본으로 비교하는 벤치마크를 실행했습니다: <code>ModernBERT</code>, <code>jina-XLM-RoBERTa</code>, 그리고 <code>RoBERTa-large</code>. 테스트는 <a href="https://github.com/github/CodeSearchNet">CodeSearchNet</a> - 텍스트 설명을 코드 스니펫과 매칭하는 것이었습니다. ModernBERT는 전반적으로 두 대안을 모두 능가했습니다.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2025/01/code_search_net.v3.svg" class="kg-image" alt="" width="787" height="489" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">이 격차는 이해가 됩니다 - </span><code spellcheck="false" style="white-space: pre-wrap;"><span>jina-XLM-RoBERTa</span></code><span style="white-space: pre-wrap;">와 </span><code spellcheck="false" style="white-space: pre-wrap;"><span>RoBERTa-large</span></code><span style="white-space: pre-wrap;"> 모두 훈련 중에 프로그래밍 언어를 접하지 않았습니다. 반면, ModernBERT-large는 상당한 양의 코드를 포함한 2조 개의 토큰으로 훈련되었습니다. 이러한 프로그래밍 구문과 패턴에 대한 노출은 코드 관련 작업에서 명확한 이점을 제공합니다. </span><code spellcheck="false" style="white-space: pre-wrap;"><span>jina-XLM-RoBERTa</span></code><span style="white-space: pre-wrap;">가 </span><code spellcheck="false" style="white-space: pre-wrap;"><span>RoBERTa-large</span></code><span style="white-space: pre-wrap;">보다 약간 앞서는 것은 더 큰 다국어 훈련 데이터 때문일 것입니다 - 같은 아키텍처에 더 많은 노출이 있었기 때문입니다. 그럼에도 불구하고, 둘 다 ModernBERT-large에 크게 뒤처집니다.</span></figcaption></figure>

<table>
<thead>
<tr>
<th>작업</th>
<th>ModernBERT-large</th>
<th><code>jina-XLM-RoBERTa</code></th>
<th><code>RoBERTa-large</code></th>
</tr>
</thead>
<tbody>
<tr>
<td>AdvRetrieval</td>
<td>0.342</td>
<td><strong>0.363</strong></td>
<td>0.331</td>
</tr>
<tr>
<td>QueryRetrieval.python</td>
<td>0.521</td>
<td><strong>0.530</strong></td>
<td>0.525</td>
</tr>
<tr>
<td>QueryRetrieval java</td>
<td><strong>0.679</strong></td>
<td>0.633</td>
<td>0.644</td>
</tr>
<tr>
<td>QueryRetrieval.javascript</td>
<td>0.755</td>
<td><strong>0.768</strong></td>
<td>0.732</td>
</tr>
<tr>
<td>QueryRetrieval.php</td>
<td><strong>0.815</strong></td>
<td>0.781</td>
<td>0.755</td>
</tr>
<tr>
<td>QueryRetrieval.ruby</td>
<td>0.729</td>
<td><strong>0.744</strong></td>
<td>0.722</td>
</tr>
<tr>
<td>QueryRetrieval.go</td>
<td><strong>0.833</strong></td>
<td>0.809</td>
<td>0.796</td>
</tr>
<tr>
<td>Retrieval.go</td>
<td><strong>0.778</strong></td>
<td>0.750</td>
<td>0.759</td>
</tr>
<tr>
<td>Retrieval.java</td>
<td><strong>0.840</strong></td>
<td>0.792</td>
<td>0.796</td>
</tr>
<tr>
<td>Retrieval.javascript</td>
<td><strong>0.817</strong></td>
<td>0.792</td>
<td>0.757</td>
</tr>
<tr>
<td>Retrieval.php</td>
<td><strong>0.852</strong></td>
<td>0.805</td>
<td>0.796</td>
</tr>
<tr>
<td>Retrieval.python</td>
<td><strong>0.849</strong></td>
<td>0.816</td>
<td>0.787</td>
</tr>
<tr>
<td>Retrieval.ruby</td>
<td><strong>0.849</strong></td>
<td>0.796</td>
<td>0.803</td>
</tr>
<tr>
<td>Avg.</td>
<td><strong>0.743</strong></td>
<td>0.721</td>
<td>0.708</td>
</tr>
</tbody>
</table>

<h3 id="the-tokenizer-edge" style="position: relative;"><a href="#the-tokenizer-edge" title="토크나이저의 장점" id="anchor-the-tokenizer-edge"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>토크나이저의 장점</h3><p>ModernBERT가 코드를 잘 다루는 이유를 살펴보겠습니다. ModernBERT는 표준 BERT/RoBERTa 토크나이저 대신 코드 학습에 특화된 <a href="https://huggingface.co/docs/transformers/en/model_doc/olmo" rel="noreferrer">OLMo 토크나이저</a>를 사용합니다.</p><p>토크나이저는 UTF-8 텍스트를 벡터로 매핑되는 토큰으로 분할합니다. 이는 모델이 실제로 처리하는 대상입니다. 학습 과정에서 자주 발생하는 문자열을 단일 토큰으로 결합하는 방법을 학습합니다. 차이점은 무엇일까요? 표준 토크나이저는 <code>init</code>를 <code>in</code> + <code>it</code>으로 분할하여 프로그래밍 컨텍스트를 놓칠 수 있습니다. 하지만 ModernBERT의 코드 인식 토크나이저는 이를 분할하지 않고 그대로 처리합니다.</p><p>공백 처리에서 흥미로운 점이 있습니다. ModernBERT는 Python의 선행 공백을 단일 토큰으로 유지하고 4개와 8개의 공백을 구분합니다 - 이는 코드 구조에 매우 중요합니다. 반면에 <strong><code>jina-XLM-RoBERTa</code>는 연속된 모든 공백을 단일 <code>_</code>로 축소하고, RoBERTa-large는 각 공백을 개별 토큰으로 처리합니다.</strong> 이는 ModernBERT의 인코더가 코드를 처리할 때 더 깔끔하고 의미 있는 입력을 받는 반면, 다른 모델들은 분절되고 덜 일관된 토큰으로 작업한다는 것을 의미합니다.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2025/01/code_tokens-cheat-2.svg" class="kg-image" alt="" width="3156" height="1247" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">ModernBERT는 Python의 선행 공백을 단일 토큰으로 유지하고 4개와 8개의 공백을 구분합니다 - 이는 코드 구조에 매우 중요합니다. 반면 다른 모델들은 분절되고 덜 일관된 토큰으로 작업합니다.</span></figcaption></figure><h2 id="modernberts-long-context-handling" style="position: relative;"><a href="#modernberts-long-context-handling" title="ModernBERT의 긴 컨텍스트 처리" id="anchor-modernberts-long-context-handling"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>ModernBERT의 긴 컨텍스트 처리</h2><p>ModernBERT는 방대한 학습 코퍼스(8,192 토큰 샘플로 구성된 300B 토큰)와 전역 및 지역 어텐션을 결합한 고급 기술 덕분에 긴 텍스트 처리에서 큰 진전을 이루었습니다.</p><p>긴 문서 처리 능력을 평가하기 위해 13개 언어를 포괄하는 종합적인 긴 텍스트 벤치마크인 <a href="https://huggingface.co/datasets/Shitao/MLDR">MLDR 데이터셋</a>을 사용했습니다. ModernBERT가 현재 영어만 지원하므로, ModernBERT와 <code>jina-XLM-RoBERTa</code>를 벤치마크하기 위해 MLDR의 영어 부분집합에 초점을 맞췄습니다. 두 모델 모두 8K 토큰 입력을 처리할 수 있지만, <code>RoBERTa-large</code>는 512 토큰 제한으로 인해 긴 텍스트 분석에 부적합하여 이 벤치마크에서 제외되었습니다.</p>

<table>
<thead>
<tr>
<th></th>
<th>ModernBERT-large</th>
<th><code>jina-XLM-RoBERTa</code></th>
</tr>
</thead>
<tbody>
<tr>
<td>MLDR-en</td>
<td><strong>0.351</strong></td>
<td>0.290</td>
</tr>
</tbody>
</table>

<p>ModernBERT의 우수한 성능은 단순히 광범위한 긴 텍스트 학습 때문만이 아닙니다. 전역 및 지역 어텐션 메커니즘의 혁신적인 조합 덕분입니다. <code>jina-XLM-RoBERTa</code>가 모든 레이어에 계산 비용이 많이 드는 전역 어텐션을 적용하는 것과 달리, ModernBERT는 더 효율적인 접근 방식을 취합니다. 전역 어텐션(3번째 레이어마다 사용되며 <code>theta</code>는 160,000)과 지역 어텐션(128 토큰 슬라이딩 윈도우 사용, <code>theta</code>는 100,000)을 번갈아 사용합니다. 이러한 하이브리드 전략은 높은 성능을 유지하면서 학습 시간을 크게 단축합니다.</p><blockquote>ModernBERT에서는 3번째 레이어마다 RoPE theta 160,000의 전역 어텐션을 사용하고, 나머지 레이어는 RoPE theta 10,000의 128 토큰 지역 슬라이딩 윈도우 어텐션을 사용합니다. —— <a href="https://arxiv.org/pdf/2412.13663">ModernBERT</a></blockquote><h2 id="the-bitter-lesson" style="position: relative;"><a href="#the-bitter-lesson" title="쓴 교훈?" id="anchor-the-bitter-lesson"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>쓴 교훈?</h2><p>스케일링 법칙과 <a href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html">쓴 교훈</a>은 주요 성능 향상이 주로 파라미터 수와 학습 데이터 증가에서 온다고 제시합니다. 이 원칙은 코퍼스를 확장하고 작업별 적응을 위해 LoRA를 사용하는 우리의 접근 방식을 이끌었습니다.</p><p>하지만 ModernBERT의 성공은 우리가 아키텍처 최적화의 힘을 과소평가했음을 보여줍니다. 이는 SLM이 반드시 파라미터를 늘리지 않고도 더 나은 데이터-모델 효율성을 통해 뛰어난 결과를 달성할 수 있음을 보여줍니다. 최근 <a href="https://arxiv.org/pdf/2408.11868">Stella Embeddings 기술 보고서</a>는 이러한 발견을 강화하며, 현재의 임베딩 모델 학습 방법이 코퍼스나 모델 크기를 늘리지 않고도 개선될 수 있음을 보여줍니다.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img loading="lazy" src="https://jina-ai-gmbh.ghost.io/content/images/2024/09/plot--4-.svg" class="kg-image" alt="Graph showing Scaling Law of Embedding Models with 'Parameter Size' on the x-axis and 'MTEB Performance' on the y-axis, featu" width="949" height="949" style="cursor: help;"><figcaption><span style="white-space: pre-wrap;">임베딩 모델의 스케일링 법칙. 영어 작업에 대한 평균 MTEB 성능이 모델 파라미터 수에 대해 플롯되었습니다. 각 점은 임베딩 모델을 나타냅니다. 모든 모델을 나타내는 추세선이 강조되어 있고, 다국어 모델은 시안색으로 강조되어 있습니다. </span><a class="dynamic-model-name" href="/?sui&amp;model=jina-embeddings-v3" target="_blank"><span class="dynamic-model-name-inner">jina-embeddings-v3</span></a><span style="white-space: pre-wrap;">가 유사한 크기의 모델들보다 우수한 성능을 보여주며, 이전 버전인 </span><code spellcheck="false" style="white-space: pre-wrap;"><span>jina-embeddings-v2</span></code><span style="white-space: pre-wrap;">보다 초선형적 개선을 보여줍니다. 이 그래프는 MTEB 리더보드에서 상위 100개 임베딩 모델을 선택하여 작성되었으며, 크기 정보가 없는 모델(일반적으로 비공개 또는 독점 모델)은 제외되었습니다. 명백한 트롤링으로 확인된 제출도 필터링되었습니다. </span></figcaption></figure><p>앞으로 데이터 활용에 대한 더 깊은 통찰력을 얻고 ModernBERT의 기술을 구현함에 따라 계산 비용과 모델 크기가 감소할 것으로 예상됩니다. 단기적으로는 ModernBERT 논문에 설명된 간단한 개선 사항을 구현할 수 있습니다 - 특히 더 많은 코드 관련 데이터를 통합하고 코드 친화적인 토크나이저를 도입하는 것입니다. deep-and-thin 아키텍처로 전환하거나 작은 모델에서 큰 모델을 부트스트랩하는 것과 같은 더 복잡한 변경은 백본 모델을 처음부터 구축해야 하는 중기적 과제가 될 것입니다.</p><p>ModernBERT의 효율성은 주목할 만하지만, 텍스트만 처리할 수 있다는 한계는 미래의 과제를 보여줍니다. 멀티모달 임베딩 모델이 인기를 얻으면서, 우리의 다음 과제는 멀티모달 애플리케이션을 위한 입력을 처리할 수 있는 더 스마트하고 빠르며 유능한 검색 기반 모델을 개발하는 것입니다. 이러한 애플리케이션은 더 긴 컨텍스트 윈도우를 요구하며 - 이는 아직 해결해야 할 효율성 과제입니다.</p><h2 id="conclusion" style="position: relative;"><a href="#conclusion" title="결론" id="anchor-conclusion"><i class="material-symbols-sharp header-hash" style="margin-right: 8px; cursor: pointer; font-size: 0.8em; opacity: 0; transition: opacity 0.2s ease 0s;">tag</i></a>결론</h2><p>이 글에서 우리는 ModernBERT가 deep-and-thin 아키텍처, 최적화된 토크나이저, 웨이트 타일링을 통한 효율적인 스케일링이라는 세 가지 핵심 혁신을 통해 BERT 계열 모델을 어떻게 발전시켰는지 살펴보았습니다. 이러한 개선으로 ModernBERT는 상대적으로 작은 크기로도 다양한 작업에서 <code>RoBERTa-large</code>와 <code>jina-XLM-RoBERTa</code> 모두를 능가하는 뛰어난 성능을 제공할 수 있습니다. ModernBERT는 아키텍처 개선이 파라미터 크기보다 더 중요할 수 있음을 보여주며, 더 효율적인 모델의 가능성을 열어줍니다. 웨이트 타일링의 성공적인 활용은 학습 비용을 줄이면서도 성능을 유지하거나 향상시킬 수 있는 방법을 보여줍니다. 또한 작은 어휘와 목표지향적 최적화는 자원이 제한된 환경에서 특화된 SLM의 기회가 증가하고 있음을 시사합니다.</p></section></article><div data-v-c36e4d4e="" class="row justify-between items-center q-py-md"><div data-v-c36e4d4e=""><span data-v-c36e4d4e="" class="text-weight-bold">범주:</span><span data-v-c36e4d4e="" class="q-ml-md"><div class="q-chip row inline no-wrap items-center q-chip--outline q-chip--square q-chip--dark q-dark non-selectable no-border-radius" style="font-size: 10px;"><div class="q-chip__content col row no-wrap items-center q-anchor--skip"><div class="ellipsis">기술 기사</div></div></div></span></div><div data-v-c36e4d4e=""><div data-v-c36e4d4e="" class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square inline"><a data-v-c36e4d4e="" href="https://news.ycombinator.com/submitlink?u=http%3A%2F%2F127.0.0.1%3A3000%2Fko%2Fnews%2Fwhat-should-we-learn-from-modernbert%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with HackerNews. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-hacker-news" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" href="https://www.linkedin.com/sharing/share-offsite/?url=http%3A%2F%2F127.0.0.1%3A3000%2Fko%2Fnews%2Fwhat-should-we-learn-from-modernbert%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with LinkedIn. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-linkedin" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" href="https://twitter.com/intent/tweet?url=http%3A%2F%2F127.0.0.1%3A3000%2Fko%2Fnews%2Fwhat-should-we-learn-from-modernbert%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Twitter. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-x-twitter" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2F127.0.0.1%3A3000%2Fko%2Fnews%2Fwhat-should-we-learn-from-modernbert%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Facebook. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-facebook" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" href="https://reddit.com/submit?url=http%3A%2F%2F127.0.0.1%3A3000%2Fko%2Fnews%2Fwhat-should-we-learn-from-modernbert%2F" target="_blank" rel="nofollow noopener noreferrer" aria-label="Share this with Reddit. (opens in new window)"><button data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square text-white q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" type="button"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-reddit" aria-hidden="true" role="img"> </i></span></button></a><a data-v-c36e4d4e="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable q-btn--square q-py-lg" tabindex="0" href="https://jina.ai/feed.rss" target="_blank"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="img">rss_feed</i></span></a></div></div></div></div></div></div></div></main></div><div data-v-478b3f77="" class="q-card q-card--dark q-dark q-card--flat no-shadow print-hide q-py-xl q-px-sm-sm q-px-xs-xs q-px-md-xl bg-dark-page q-gutter-y-xl q-mt-xl"><div data-v-478b3f77="" class="q-card__section q-card__section--vert row q-gutter-y-xl q-pa-none"><div data-v-478b3f77="" class="col-sm-12 col-md"><div data-v-478b3f77="" class="q-list q-list--dark small-font-on-mobile" role="list"><div data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">사무실</div><div data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-478b3f77="" class="q-item__section column q-item__section--side q-item__section--top justify-start"><i data-v-478b3f77="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center"><div data-v-478b3f77="" class="q-item__label">캘리포니아주 서니베일</div><div data-v-478b3f77="" class="q-item__label q-item__label--caption text-caption text-dim">710 Lakeway Dr, Ste 200, 서니베일, CA 94085, 미국</div></div></div><div data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-478b3f77="" class="q-item__section column q-item__section--side q-item__section--top justify-start"><i data-v-478b3f77="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center"><div data-v-478b3f77="" class="q-item__label">독일 베를린(본사)</div><div data-v-478b3f77="" class="q-item__label q-item__label--caption text-caption text-dim">Prinzessinnenstraße 19-20, 10969 베를린, 독일</div></div></div><div data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-478b3f77="" class="q-item__section column q-item__section--side q-item__section--top justify-start"><i data-v-478b3f77="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center"><div data-v-478b3f77="" class="q-item__label">중국 베이징</div><div data-v-478b3f77="" class="q-item__label q-item__label--caption text-caption text-dim">중국 베이징 하이뎬구 서가 48호 6호관 5층</div></div></div><div data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark" role="listitem"><div data-v-478b3f77="" class="q-item__section column q-item__section--side q-item__section--top justify-start"><i data-v-478b3f77="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 24px;">location_on</i></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center"><div data-v-478b3f77="" class="q-item__label">중국 선전</div><div data-v-478b3f77="" class="q-item__label q-item__label--caption text-caption text-dim">중국 선전 푸안 테크놀로지 빌딩 4층 402호</div></div></div></div></div><div data-v-478b3f77="" class="col-sm-12 col-md row"><div data-v-478b3f77="" class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">검색 기반</div><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/deepsearch"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">심층 검색</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/reader"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">리더</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/embeddings"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">벡터 모델</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/reranker"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">재배열자</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/classifier"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">분류자</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dense q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/segmenter"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">얇게 써는 기계</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://docs.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">API 문서</div></a><div data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">Jina API 키 받기</div></div><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/contact-sales#rate-limit"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">비율 제한</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://status.jina.ai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--side justify-center q-pa-none"><svg data-v-478b3f77="" class="q-spinner text-green-13 q-mr-xs" stroke="currentColor" width="1em" height="1em" viewBox="0 0 45 45" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd" transform="translate(1 1)" stroke-width="2"><circle cx="22" cy="22" r="6"><animate attributeName="r" begin="1.5s" dur="3s" values="6;22" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-opacity" begin="1.5s" dur="3s" values="1;0" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-width" begin="1.5s" dur="3s" values="2;0" calcMode="linear" repeatCount="indefinite"></animate></circle><circle cx="22" cy="22" r="6"><animate attributeName="r" begin="3s" dur="3s" values="6;22" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-opacity" begin="3s" dur="3s" values="1;0" calcMode="linear" repeatCount="indefinite"></animate><animate attributeName="stroke-width" begin="3s" dur="3s" values="2;0" calcMode="linear" repeatCount="indefinite"></animate></circle><circle cx="22" cy="22" r="8"><animate attributeName="r" begin="0s" dur="1.5s" values="6;1;2;3;4;5;6" calcMode="linear" repeatCount="indefinite"></animate></circle></g></svg></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">API 상태</div></a></div><div data-v-478b3f77="" class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">회사</div><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/about-us"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">회사 소개</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/contact-sales"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">영업팀에 문의</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/news"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">소식</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/internship"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">인턴 프로그램</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="https://app.dover.com/jobs/jinaai" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">우리와 함께</div><div data-v-478b3f77="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i data-v-478b3f77="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 18px;">open_in_new</i></div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/logo-Jina-1024.zip" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">로고 다운로드</div><div data-v-478b3f77="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><i data-v-478b3f77="" class="q-icon notranslate material-symbols material-symbols-sharp" aria-hidden="true" role="presentation" style="font-size: 18px;">open_in_new</i></div></a></div><div data-v-478b3f77="" class="q-list q-list--dense q-list--dark col small-font-on-mobile" role="list"><div data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark text-uppercase" role="listitem">자귀</div><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal#security-as-company-value"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">안전</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal/#terms-and-conditions"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">이용약관</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="/legal/#privacy-policy"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">은둔</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable text-dim" role="listitem" tabindex="0" href="javascript:UC_UI.showSecondLayer();"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--main justify-center">쿠키 관리</div></a><a data-v-478b3f77="" class="q-item q-item-type row no-wrap q-item--dark q-item--clickable q-link cursor-pointer q-focusable q-hoverable" role="listitem" tabindex="0" href="https://app.eu.vanta.com/jinaai/trust/vz7f4mohp0847aho84lmva" target="_blank"><div class="q-focus-helper" tabindex="-1"></div><div data-v-478b3f77="" class="q-item__section column q-item__section--side justify-center q-item__section--avatar"><div data-v-478b3f77="" class="q-img q-img--menu soc-icon is-mobile" role="img"><div style="padding-bottom: 99.3377%;"></div><div class="q-img__container absolute-full"><img class="q-img__image q-img__image--with-transition q-img__image--loaded" loading="lazy" fetchpriority="auto" aria-hidden="true" draggable="false" src="/21972-312_SOC_NonCPA_Blk.svg" style="object-fit: cover; object-position: 50% 50%;"></div><div class="q-img__content absolute-full q-anchor--skip"></div></div></div></a></div></div></div><div data-v-478b3f77="" class="q-card__section q-card__section--vert row q-gutter-y-xl items-center justify-center q-pa-none"><div data-v-478b3f77="" class="q-btn-group row no-wrap q-btn-group--flat q-btn-group--square q-btn-group--stretch inline col-12 col-md"><a data-v-478b3f77="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://x.com/jinaAI_" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-x-twitter" aria-hidden="true" role="img"> </i></span></a><a data-v-478b3f77="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://www.linkedin.com/company/jinaai/" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-linkedin" aria-hidden="true" role="img"> </i></span></a><a data-v-478b3f77="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://github.com/jina-ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-github" aria-hidden="true" role="img"> </i></span></a><a data-v-478b3f77="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://huggingface.co/jinaai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon" aria-hidden="true" role="img"><img src="/huggingface_logo.svg"></i></span></a><a data-v-478b3f77="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="https://discord.jina.ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-discord" aria-hidden="true" role="img"> </i></span></a><button data-v-478b3f77="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" type="button" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon fab fa-weixin" aria-hidden="true" role="img"> </i></span></button><a data-v-478b3f77="" class="q-btn q-btn-item non-selectable no-outline q-btn--flat q-btn--rectangle q-btn--square q-btn--actionable q-focusable q-hoverable no-border-radius self-stretch q-btn--square" tabindex="0" href="mailto:support@jina.ai" target="_blank" style="font-size: 10px;"><span class="q-focus-helper"></span><span class="q-btn__content text-center col items-center q-anchor--skip justify-center row"><i class="q-icon notranslate material-symbols material-symbols-sharp material-symbols-sharp-filled" aria-hidden="true" role="img">email</i></span></a></div><div data-v-478b3f77="" class="row items-center justify-end q-gutter-x-sm col-12 col-md"><div class="text-caption text-dim"> Jina AI © 2020-2025. </div></div></div></div></div></div><div id="q-notify" data-v-app=""><div class="q-notifications"><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-start"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-end"></div><div class="q-notifications__list q-notifications__list--top fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--bottom fixed column no-wrap items-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-start justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap items-end justify-center"></div><div class="q-notifications__list q-notifications__list--center fixed column no-wrap flex-center"></div></div></div></body></html>